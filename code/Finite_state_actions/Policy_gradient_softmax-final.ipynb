{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Policy gradient for finite state finite action MDPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nSet-up:\\n1) Softmax policy \\n2) Bounded rewards\\n3) Many states and actions\\n4) Classic policy gradient\\n5) Stochastic version\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Set-up:\n",
    "1) Softmax policy \n",
    "2) Bounded rewards\n",
    "3) Many states and actions\n",
    "4) Classic policy gradient\n",
    "5) Stochastic version\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.set_printoptions(formatter={'float': lambda x: \"{0:0.6f}\".format(x)})\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Random Seed\n",
    "np.random.seed(10) \n",
    "## Problem Setup\n",
    "gamma = 0.9\n",
    "n, m = 50, 10\n",
    "'''\n",
    "Randomly generated probability transition matrix P((s,a) -> s') in R^{|S||A| x |S|}\n",
    "Each row sums up to one\n",
    "'''\n",
    "raw_transition = np.random.uniform(0,1,size=(n*m,n))\n",
    "prob_transition = raw_transition/raw_transition.sum(axis=1,keepdims=1)\n",
    "'''\n",
    "Random positive rewards\n",
    "'''\n",
    "reward = np.random.uniform(0,1,size=(n*m))\n",
    "'''\n",
    "Start state distribution\n",
    "'''\n",
    "rho = np.ones(n)/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Input: theta as an array and \n",
    "Ouput: array of probabilites corresponding to each state: [\\pi_{s_1}(.), ...., \\pi_{s_n}(.)]\n",
    "'''\n",
    "def theta_to_policy(theta,n,m):\n",
    "    prob = []\n",
    "    for i in range(n):\n",
    "        norm = np.sum(np.exp(theta[m*i:m*(i+1)]))\n",
    "        for j in range(m*i,m*(i+1)):\n",
    "            prob.append(np.exp(theta[j])/norm)\n",
    "            \n",
    "    return np.asarray(prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Get \\Pi_{\\pi}((s) -> (s,a)) in R^{|S| x |S||A|} matrix corresponding to the policy \\pi using the prob vector\n",
    "'''\n",
    "def get_Pi(prob,n,m):\n",
    "    Pi = np.zeros((n,n*m))\n",
    "    for i in range(n):\n",
    "        Pi[i,i*m:(i+1)*m] = prob[i*m:(i+1)*m]\n",
    "    \n",
    "    return Pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Input: probability vector, state, action\n",
    "Output: \\nabla_{\\theta} \\pi_{\\theta}(s,a)\n",
    "\n",
    "States go from 0 to n-1 and actons from 0 to m-1\n",
    "'''\n",
    "def grad_state_action(prob,state,action):\n",
    "    grad = np.zeros(n*m)\n",
    "    for j in range(0,m):\n",
    "        if j == action:\n",
    "            grad[m*state + j] = prob[m*state + j]*(1-prob[m*state + j])\n",
    "        else:\n",
    "            grad[m*state + j] = -prob[m*state + action]*prob[m*state + j]\n",
    "            \n",
    "    return grad\n",
    "\n",
    "def grad_state(qvals,prob,state):\n",
    "    grad = np.sum([qvals[state*m + i]*grad_state_action(prob,state,i) for i in range(0,m)],axis=0)\n",
    "    return grad\n",
    "\n",
    "def grad(qvals,prob,d_pi):\n",
    "    grad = np.sum([d_pi[i]*grad_state(qvals,prob,i) for i in range(0,n)],axis=0)\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "The overall reward function \\ell(\\theta)\n",
    "'''\n",
    "def ell(qvals,prob,rho):\n",
    "    V = np.zeros(n)\n",
    "    for i in range(n):\n",
    "        V[i] = np.sum([qvals[i*m + j]*prob[i*m + j] for j in range(m)])\n",
    "    \n",
    "    ell = np.dot(V,rho)\n",
    "    return ell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Policy Iteration to get the optimal policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_vec = np.random.uniform(0,1,size=(n,m))\n",
    "prob_vec = raw_vec/raw_vec.sum(axis=1,keepdims=1)\n",
    "init_policy = prob_vec.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Policy iteration function\n",
    "'''\n",
    "def policy_iter(q_vals,n,m):\n",
    "    new_policy = np.zeros(n*m)\n",
    "    for i in range(n):\n",
    "        idx = np.argmax(q_vals[i*m:(i+1)*m])\n",
    "        new_policy[i*m + idx] = 1\n",
    "    \n",
    "    return new_policy       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Starting policy', array([0.183601, 0.042136, 0.188186, 0.015895, 0.101761, 0.104776,\n",
      "       0.135518, 0.129841, 0.057457, 0.040828, 0.162577, 0.042117,\n",
      "       0.189594, 0.037847, 0.121255, 0.114304, 0.148011, 0.133611,\n",
      "       0.047052, 0.003632, 0.044615, 0.154131, 0.157930, 0.120999,\n",
      "       0.110072, 0.054127, 0.064022, 0.116231, 0.119174, 0.058697,\n",
      "       0.083538, 0.167552, 0.227608, 0.171042, 0.071159, 0.018789,\n",
      "       0.022177, 0.039207, 0.105754, 0.093176, 0.112182, 0.052303,\n",
      "       0.088935, 0.067892, 0.190792, 0.129395, 0.037790, 0.050349,\n",
      "       0.076216, 0.194146, 0.023965, 0.095530, 0.092327, 0.163325,\n",
      "       0.172240, 0.015720, 0.159156, 0.080971, 0.170116, 0.026650,\n",
      "       0.092263, 0.087358, 0.000253, 0.218909, 0.214072, 0.071979,\n",
      "       0.140169, 0.024056, 0.105316, 0.045625, 0.084422, 0.086093,\n",
      "       0.155112, 0.138068, 0.183422, 0.067583, 0.049054, 0.128301,\n",
      "       0.017517, 0.090429, 0.079617, 0.129940, 0.075708, 0.099232,\n",
      "       0.111134, 0.138348, 0.179186, 0.023041, 0.032961, 0.130834,\n",
      "       0.005614, 0.037318, 0.160651, 0.132142, 0.123873, 0.132109,\n",
      "       0.160274, 0.189380, 0.025692, 0.032947, 0.158746, 0.123539,\n",
      "       0.116917, 0.121922, 0.061491, 0.146647, 0.031329, 0.048851,\n",
      "       0.049527, 0.141032, 0.132520, 0.135319, 0.101106, 0.100649,\n",
      "       0.162614, 0.159596, 0.016637, 0.009740, 0.014931, 0.166887,\n",
      "       0.046389, 0.153891, 0.142402, 0.004969, 0.114971, 0.077341,\n",
      "       0.158875, 0.121747, 0.045989, 0.133426, 0.046969, 0.092650,\n",
      "       0.062988, 0.153614, 0.055412, 0.155433, 0.018692, 0.152416,\n",
      "       0.151570, 0.110259, 0.217619, 0.190322, 0.058856, 0.003272,\n",
      "       0.005635, 0.015247, 0.185674, 0.138229, 0.160401, 0.024743,\n",
      "       0.120387, 0.169695, 0.088137, 0.053754, 0.087404, 0.002094,\n",
      "       0.164029, 0.062642, 0.129544, 0.122314, 0.177599, 0.095355,\n",
      "       0.032023, 0.025176, 0.144113, 0.164705, 0.178246, 0.017662,\n",
      "       0.157617, 0.007504, 0.149169, 0.030965, 0.034783, 0.187043,\n",
      "       0.079712, 0.091409, 0.126895, 0.172403, 0.098612, 0.029010,\n",
      "       0.106016, 0.061237, 0.021684, 0.118514, 0.078600, 0.018416,\n",
      "       0.070913, 0.247256, 0.078319, 0.199044, 0.118510, 0.100237,\n",
      "       0.049594, 0.096499, 0.186316, 0.095242, 0.014198, 0.130677,\n",
      "       0.114929, 0.093800, 0.013518, 0.171267, 0.156724, 0.092502,\n",
      "       0.127169, 0.134853, 0.006607, 0.074866, 0.056405, 0.166089,\n",
      "       0.094501, 0.053445, 0.147646, 0.073329, 0.143288, 0.034283,\n",
      "       0.084851, 0.150633, 0.107725, 0.110298, 0.146384, 0.033158,\n",
      "       0.160213, 0.124549, 0.099954, 0.128537, 0.027887, 0.003052,\n",
      "       0.177197, 0.099068, 0.051056, 0.132936, 0.153212, 0.046040,\n",
      "       0.109646, 0.153091, 0.162614, 0.073862, 0.051416, 0.066127,\n",
      "       0.254026, 0.028813, 0.008361, 0.082645, 0.125568, 0.092854,\n",
      "       0.139315, 0.108762, 0.126078, 0.033578, 0.197877, 0.041859,\n",
      "       0.010101, 0.111272, 0.187890, 0.107004, 0.163547, 0.023348,\n",
      "       0.059534, 0.097570, 0.089258, 0.091591, 0.050251, 0.152884,\n",
      "       0.166092, 0.042352, 0.053197, 0.129984, 0.077100, 0.147291,\n",
      "       0.003233, 0.085894, 0.139161, 0.046496, 0.080394, 0.205725,\n",
      "       0.130192, 0.076656, 0.046100, 0.186148, 0.149293, 0.124441,\n",
      "       0.104271, 0.122692, 0.148546, 0.062527, 0.030458, 0.011968,\n",
      "       0.132396, 0.113410, 0.177906, 0.115392, 0.151561, 0.016571,\n",
      "       0.052837, 0.143384, 0.053757, 0.051332, 0.233263, 0.003997,\n",
      "       0.204600, 0.070014, 0.041253, 0.044823, 0.029259, 0.185681,\n",
      "       0.052234, 0.024800, 0.201901, 0.145435, 0.084180, 0.056820,\n",
      "       0.117354, 0.020692, 0.129421, 0.128316, 0.099582, 0.154762,\n",
      "       0.143052, 0.065822, 0.135831, 0.153787, 0.091070, 0.138049,\n",
      "       0.059700, 0.024805, 0.013770, 0.082259, 0.169101, 0.131629,\n",
      "       0.033293, 0.137674, 0.061312, 0.178881, 0.039868, 0.110356,\n",
      "       0.192732, 0.039283, 0.201266, 0.005335, 0.115027, 0.019843,\n",
      "       0.049996, 0.045557, 0.063986, 0.214989, 0.215562, 0.135246,\n",
      "       0.085382, 0.054414, 0.132626, 0.138635, 0.068464, 0.110135,\n",
      "       0.092824, 0.097517, 0.059384, 0.111280, 0.056667, 0.132467,\n",
      "       0.073349, 0.125961, 0.138583, 0.127232, 0.083768, 0.139214,\n",
      "       0.035214, 0.083448, 0.055184, 0.138049, 0.189922, 0.170604,\n",
      "       0.054488, 0.154614, 0.082675, 0.103101, 0.054924, 0.096115,\n",
      "       0.040344, 0.053212, 0.099584, 0.082114, 0.165878, 0.016369,\n",
      "       0.042980, 0.159791, 0.135827, 0.132279, 0.019763, 0.145416,\n",
      "       0.179152, 0.109046, 0.178304, 0.009468, 0.022783, 0.056162,\n",
      "       0.092051, 0.146949, 0.154973, 0.051110, 0.073356, 0.174817,\n",
      "       0.005279, 0.032533, 0.166917, 0.177566, 0.149778, 0.037717,\n",
      "       0.051919, 0.130117, 0.161556, 0.155264, 0.104635, 0.005211,\n",
      "       0.128662, 0.096828, 0.129671, 0.146619, 0.061445, 0.010110,\n",
      "       0.085418, 0.105070, 0.065578, 0.117052, 0.181927, 0.117404,\n",
      "       0.164641, 0.109305, 0.046969, 0.006637, 0.118867, 0.022853,\n",
      "       0.108005, 0.079356, 0.036101, 0.121651, 0.147560, 0.132617,\n",
      "       0.108242, 0.124750, 0.144941, 0.120317, 0.006532, 0.103422,\n",
      "       0.026894, 0.070110, 0.210985, 0.040768, 0.109896, 0.166136,\n",
      "       0.240040, 0.015056, 0.067036, 0.073822, 0.144033, 0.007571,\n",
      "       0.166917, 0.158825, 0.119202, 0.007497, 0.000495, 0.127219,\n",
      "       0.162157, 0.092437, 0.165985, 0.074111, 0.148824, 0.067269,\n",
      "       0.037932, 0.123570, 0.059505, 0.139943, 0.010011, 0.116143,\n",
      "       0.154955, 0.175731, 0.191696, 0.020212, 0.008310, 0.123494,\n",
      "       0.064307, 0.035394, 0.090848, 0.127833, 0.228823, 0.202506,\n",
      "       0.095484, 0.021852, 0.054527, 0.078425, 0.140141, 0.030803,\n",
      "       0.133828, 0.013118, 0.162841, 0.121681, 0.098015, 0.043319,\n",
      "       0.105271, 0.150983]))\n",
      "('Final policy', array([0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000,\n",
      "       0.000000, 0.000000, 1.000000, 0.000000, 0.000000, 0.000000,\n",
      "       0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000,\n",
      "       1.000000, 0.000000, 0.000000, 0.000000, 0.000000, 1.000000,\n",
      "       0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000,\n",
      "       0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000,\n",
      "       0.000000, 0.000000, 0.000000, 1.000000, 0.000000, 0.000000,\n",
      "       0.000000, 0.000000, 0.000000, 0.000000, 1.000000, 0.000000,\n",
      "       0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000,\n",
      "       0.000000, 0.000000, 0.000000, 1.000000, 0.000000, 0.000000,\n",
      "       0.000000, 1.000000, 0.000000, 0.000000, 0.000000, 0.000000,\n",
      "       0.000000, 0.000000, 0.000000, 0.000000, 1.000000, 0.000000,\n",
      "       0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000,\n",
      "       0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000,\n",
      "       0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 1.000000,\n",
      "       0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000,\n",
      "       0.000000, 1.000000, 0.000000, 0.000000, 0.000000, 0.000000,\n",
      "       0.000000, 0.000000, 1.000000, 0.000000, 0.000000, 0.000000,\n",
      "       0.000000, 0.000000, 0.000000, 1.000000, 0.000000, 0.000000,\n",
      "       0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000,\n",
      "       0.000000, 0.000000, 1.000000, 0.000000, 0.000000, 0.000000,\n",
      "       0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000,\n",
      "       0.000000, 0.000000, 0.000000, 1.000000, 0.000000, 0.000000,\n",
      "       0.000000, 0.000000, 0.000000, 1.000000, 0.000000, 0.000000,\n",
      "       0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000,\n",
      "       0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000,\n",
      "       1.000000, 0.000000, 0.000000, 0.000000, 1.000000, 0.000000,\n",
      "       0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000,\n",
      "       0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000,\n",
      "       1.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000,\n",
      "       0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000,\n",
      "       1.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000,\n",
      "       0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000,\n",
      "       0.000000, 1.000000, 0.000000, 1.000000, 0.000000, 0.000000,\n",
      "       0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000,\n",
      "       0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000,\n",
      "       0.000000, 0.000000, 0.000000, 1.000000, 0.000000, 0.000000,\n",
      "       0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 1.000000,\n",
      "       0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000,\n",
      "       1.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000,\n",
      "       0.000000, 1.000000, 0.000000, 0.000000, 0.000000, 0.000000,\n",
      "       0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000,\n",
      "       0.000000, 0.000000, 1.000000, 0.000000, 0.000000, 0.000000,\n",
      "       0.000000, 0.000000, 0.000000, 1.000000, 0.000000, 0.000000,\n",
      "       0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000,\n",
      "       0.000000, 0.000000, 1.000000, 0.000000, 0.000000, 0.000000,\n",
      "       0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000,\n",
      "       0.000000, 0.000000, 0.000000, 1.000000, 0.000000, 0.000000,\n",
      "       0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000,\n",
      "       0.000000, 0.000000, 0.000000, 0.000000, 1.000000, 0.000000,\n",
      "       0.000000, 0.000000, 0.000000, 0.000000, 1.000000, 0.000000,\n",
      "       0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000,\n",
      "       0.000000, 0.000000, 0.000000, 1.000000, 0.000000, 0.000000,\n",
      "       0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000,\n",
      "       0.000000, 1.000000, 0.000000, 0.000000, 0.000000, 0.000000,\n",
      "       0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 1.000000,\n",
      "       0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000,\n",
      "       0.000000, 1.000000, 0.000000, 0.000000, 0.000000, 0.000000,\n",
      "       0.000000, 0.000000, 1.000000, 0.000000, 0.000000, 0.000000,\n",
      "       0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000,\n",
      "       0.000000, 0.000000, 0.000000, 1.000000, 0.000000, 0.000000,\n",
      "       0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000,\n",
      "       0.000000, 0.000000, 1.000000, 0.000000, 0.000000, 0.000000,\n",
      "       0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000,\n",
      "       0.000000, 0.000000, 1.000000, 0.000000, 0.000000, 0.000000,\n",
      "       0.000000, 0.000000, 0.000000, 0.000000, 1.000000, 0.000000,\n",
      "       0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000,\n",
      "       1.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000,\n",
      "       0.000000, 0.000000, 0.000000, 1.000000, 0.000000, 0.000000,\n",
      "       0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000,\n",
      "       0.000000, 0.000000, 0.000000, 1.000000, 0.000000, 0.000000,\n",
      "       0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000,\n",
      "       0.000000, 0.000000, 0.000000, 0.000000, 1.000000, 0.000000,\n",
      "       0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000,\n",
      "       0.000000, 0.000000, 0.000000, 0.000000, 1.000000, 0.000000,\n",
      "       0.000000, 0.000000, 1.000000, 0.000000, 0.000000, 0.000000,\n",
      "       0.000000, 0.000000, 0.000000, 0.000000, 1.000000, 0.000000,\n",
      "       0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000,\n",
      "       0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000,\n",
      "       1.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000,\n",
      "       1.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000,\n",
      "       0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000,\n",
      "       0.000000, 0.000000, 0.000000, 0.000000, 1.000000, 0.000000,\n",
      "       0.000000, 0.000000]))\n"
     ]
    }
   ],
   "source": [
    "curr_policy = np.random.uniform(0,1,size=(n*m))\n",
    "new_policy = init_policy\n",
    "print('Starting policy',init_policy)\n",
    "\n",
    "while np.count_nonzero(curr_policy - new_policy) > 0:\n",
    "    curr_policy = new_policy\n",
    "    Pi = get_Pi(curr_policy,n,m)\n",
    "    mat = np.identity(n*m) - gamma*np.matmul(prob_transition,Pi)\n",
    "    q_vals = np.dot(np.linalg.inv(mat),reward)\n",
    "    new_policy = policy_iter(q_vals,n,m)\n",
    "    \n",
    "print('Final policy',new_policy)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.22755866971112\n"
     ]
    }
   ],
   "source": [
    "ell_star = ell(q_vals,new_policy,rho)\n",
    "print(ell_star)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backtracking line search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ell_theta(theta,rho):\n",
    "    prob = theta_to_policy(theta,n,m)\n",
    "    Pi = get_Pi(prob,n,m)\n",
    "    mat = np.identity(n*m) - gamma*np.matmul(prob_transition,Pi)\n",
    "    qvals = np.dot(np.linalg.inv(mat),reward)\n",
    "    return ell(qvals,prob,rho)\n",
    "       \n",
    "def find_step(theta,gradient,alpha,beta):\n",
    "    step = alpha\n",
    "    while ell_theta(theta - step*gradient,rho) > ell_theta(theta,rho) - (step/2)*np.linalg.norm(gradient):\n",
    "        step = beta*step\n",
    "    return step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Policy gradient in action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Optimality gap', 4.135801820921956)\n",
      "('Optimality gap', 3.9692284028437292)\n",
      "('Optimality gap', 3.804549304319872)\n",
      "('Optimality gap', 3.6406088134533716)\n",
      "('Optimality gap', 3.4762384913806503)\n",
      "('Optimality gap', 3.3104595461723116)\n",
      "('Optimality gap', 3.142928397287675)\n",
      "('Optimality gap', 2.974429661299504)\n",
      "('Optimality gap', 2.80675606175413)\n",
      "('Optimality gap', 2.6417738140285563)\n",
      "('Optimality gap', 2.4807026555947633)\n",
      "('Optimality gap', 2.324295330669117)\n",
      "('Optimality gap', 2.173350174993981)\n",
      "('Optimality gap', 2.028899788946992)\n",
      "('Optimality gap', 1.8920177140183894)\n",
      "('Optimality gap', 1.763545226660443)\n",
      "('Optimality gap', 1.6439641615329288)\n",
      "('Optimality gap', 1.533418878422376)\n",
      "('Optimality gap', 1.431802163523603)\n",
      "('Optimality gap', 1.3388383043632617)\n",
      "('Optimality gap', 1.2541337658907876)\n",
      "('Optimality gap', 1.1771996722807554)\n",
      "('Optimality gap', 1.107467347034909)\n",
      "('Optimality gap', 1.0443118910535674)\n",
      "('Optimality gap', 0.9870836240681768)\n",
      "('Optimality gap', 0.9351394737590315)\n",
      "('Optimality gap', 0.8878677750549944)\n",
      "('Optimality gap', 0.8447042206592403)\n",
      "('Optimality gap', 0.8051397579992337)\n",
      "('Optimality gap', 0.7687224748534547)\n",
      "('Optimality gap', 0.7350556621143642)\n",
      "('Optimality gap', 0.703793927391148)\n",
      "('Optimality gap', 0.674638786088483)\n",
      "('Optimality gap', 0.6473346810303386)\n",
      "('Optimality gap', 0.6216658672498223)\n",
      "('Optimality gap', 0.5974540315294572)\n",
      "('Optimality gap', 0.5745559810487944)\n",
      "('Optimality gap', 0.5528604489317335)\n",
      "('Optimality gap', 0.5322832724495541)\n",
      "('Optimality gap', 0.5127609424308961)\n",
      "('Optimality gap', 0.4942434512706697)\n",
      "('Optimality gap', 0.47668788323426625)\n",
      "('Optimality gap', 0.46005391353435776)\n",
      "('Optimality gap', 0.44430150704396)\n",
      "('Optimality gap', 0.42939024264283)\n",
      "('Optimality gap', 0.4152793422010461)\n",
      "('Optimality gap', 0.4019277134452359)\n",
      "('Optimality gap', 0.3892938084931288)\n",
      "('Optimality gap', 0.3773354793109558)\n",
      "('Optimality gap', 0.3660100986711967)\n",
      "('Optimality gap', 0.35527507162358596)\n",
      "('Optimality gap', 0.34508866140840944)\n",
      "('Optimality gap', 0.33541092961563734)\n",
      "('Optimality gap', 0.32620457780740253)\n",
      "('Optimality gap', 0.31743554063672264)\n",
      "('Optimality gap', 0.30907326675882807)\n",
      "('Optimality gap', 0.3010906984513184)\n",
      "('Optimality gap', 0.29346401027900626)\n",
      "('Optimality gap', 0.28617219109346337)\n",
      "('Optimality gap', 0.27919655693544776)\n",
      "('Optimality gap', 0.2725202708110057)\n",
      "('Optimality gap', 0.2661279246225927)\n",
      "('Optimality gap', 0.26000521433334)\n",
      "('Optimality gap', 0.25413871663603516)\n",
      "('Optimality gap', 0.24851575753228694)\n",
      "('Optimality gap', 0.24312435203299998)\n",
      "('Optimality gap', 0.2379531896569702)\n",
      "('Optimality gap', 0.23299164129640637)\n",
      "('Optimality gap', 0.2282297675340974)\n",
      "('Optimality gap', 0.22365831481573295)\n",
      "('Optimality gap', 0.21926869248491165)\n",
      "('Optimality gap', 0.21505292949395916)\n",
      "('Optimality gap', 0.21100361396501732)\n",
      "('Optimality gap', 0.2071138214371384)\n",
      "('Optimality gap', 0.20337703865649637)\n",
      "('Optimality gap', 0.19978708943697931)\n",
      "('Optimality gap', 0.19633806785923724)\n",
      "('Optimality gap', 0.1930242823410424)\n",
      "('Optimality gap', 0.1898402123048104)\n",
      "('Optimality gap', 0.18678047758458227)\n",
      "('Optimality gap', 0.18383981952420925)\n",
      "('Optimality gap', 0.18101309197053617)\n",
      "('Optimality gap', 0.17829526002382323)\n",
      "('Optimality gap', 0.17568140438509516)\n",
      "('Optimality gap', 0.17316672933241684)\n",
      "('Optimality gap', 0.17074657266863724)\n",
      "('Optimality gap', 0.16841641633497595)\n",
      "('Optimality gap', 0.1661718967248227)\n",
      "('Optimality gap', 0.16400881403033374)\n",
      "('Optimality gap', 0.1619231401970982)\n",
      "('Optimality gap', 0.15991102524757572)\n",
      "('Optimality gap', 0.15796880186814555)\n",
      "('Optimality gap', 0.1560929882461295)\n",
      "('Optimality gap', 0.1542802892011803)\n",
      "('Optimality gap', 0.15252759569046148)\n",
      "('Optimality gap', 0.15083198278572318)\n",
      "('Optimality gap', 0.14919070623044206)\n",
      "('Optimality gap', 0.14760119769068858)\n",
      "('Optimality gap', 0.14606105881862064)\n",
      "('Optimality gap', 0.14456805425372465)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Gradient decent\n",
    "'''\n",
    "N = 10000\n",
    "stepsize = 0.01\n",
    "# Parameters for line search\n",
    "alpha = 1\n",
    "beta = 0.7\n",
    "theta = np.random.uniform(0,1,size=n*m)\n",
    "gap = []\n",
    "for k in range(N):\n",
    "    prob = theta_to_policy(theta,n,m)\n",
    "\n",
    "    Pi = get_Pi(prob,n,m)\n",
    "    mat = np.identity(n*m) - gamma*np.matmul(prob_transition,Pi)\n",
    "    qvals = np.dot(np.linalg.inv(mat),reward)\n",
    "\n",
    "    P_theta = np.matmul(Pi,prob_transition)\n",
    "    d_pi = (1-gamma)*np.dot(np.transpose((np.linalg.inv(np.identity(n) - gamma*P_theta))),rho)\n",
    "\n",
    "    gradient = grad(qvals,prob,d_pi)\n",
    "    #     theta += stepsize*gradient\n",
    "\n",
    "    step = find_step(theta,gradient,alpha,beta)\n",
    "    theta += step*gradient\n",
    "    \n",
    "    \n",
    "    if k % 100 == 0:\n",
    "        avg_reward = ell(qvals,prob,rho)\n",
    "        print('Optimality gap',ell_star - avg_reward)\n",
    "        gap.append(ell_star - avg_reward)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Policy gap', array([-0.002074, -0.002449, -0.002539, -0.008398, -0.002302, -0.004446,\n",
      "       -0.002010, -0.431087, 0.487956, -0.032652, -0.001204, -0.019716,\n",
      "       -0.001063, -0.001860, -0.029838, -0.002194, -0.006692, -0.016371,\n",
      "       0.084836, -0.005898, -0.101884, -0.003077, -0.002320, 0.126192,\n",
      "       -0.001922, -0.003316, -0.003692, -0.001362, -0.007295, -0.001325,\n",
      "       -0.002136, -0.004545, -0.000863, -0.001988, -0.974899, -0.001886,\n",
      "       -0.000884, -0.002386, -0.005105, 0.994693, -0.001298, -0.001763,\n",
      "       -0.004211, -0.008333, -0.004856, -0.001118, 0.031314, -0.001122,\n",
      "       -0.006336, -0.002278, -0.001056, -0.001326, -0.001252, -0.001611,\n",
      "       -0.004314, -0.019955, -0.001966, 0.034950, -0.001529, -0.001942,\n",
      "       -0.001272, 0.990030, -0.002019, -0.006566, -0.004150, -0.001067,\n",
      "       -0.969462, -0.001109, -0.002450, -0.001936, 0.023158, -0.004125,\n",
      "       -0.002852, -0.002228, -0.000714, -0.000759, -0.001082, -0.002816,\n",
      "       -0.007023, -0.001560, -0.001224, -0.002945, -0.939763, -0.001678,\n",
      "       -0.004699, -0.007123, -0.001954, -0.015732, -0.002390, 0.977509,\n",
      "       -0.002787, -0.001035, -0.000958, -0.000883, -0.001490, -0.001348,\n",
      "       -0.981477, 0.994723, -0.001098, -0.003648, -0.001024, -0.001291,\n",
      "       -0.003442, -0.001181, 0.030759, -0.002298, -0.002823, -0.001217,\n",
      "       -0.001042, -0.016441, -0.031011, 0.973953, -0.003725, -0.017879,\n",
      "       -0.011498, -0.002867, -0.006513, -0.048134, -0.002776, -0.849550,\n",
      "       -0.005959, -0.004648, 0.021066, -0.002103, -0.001153, -0.002015,\n",
      "       -0.000682, -0.002487, -0.001135, -0.000884, -0.003365, -0.000775,\n",
      "       -0.001552, -0.000732, -0.017210, 0.032431, -0.000782, -0.004203,\n",
      "       -0.002583, -0.001230, -0.000980, 0.019302, -0.002963, -0.001775,\n",
      "       -0.006436, -0.001840, -0.001562, -0.001271, -0.001330, -0.001145,\n",
      "       -0.000966, -0.003057, -0.000926, -0.003439, -0.001572, -0.001751,\n",
      "       0.016405, -0.001022, -0.000929, -0.002743, 0.113260, -0.001844,\n",
      "       -0.009022, -0.002061, -0.001833, -0.001489, -0.019503, -0.058810,\n",
      "       -0.014737, -0.003961, -0.000806, -0.001064, -0.006189, -0.002270,\n",
      "       0.033813, -0.005815, -0.014159, -0.000938, -0.001685, -0.000887,\n",
      "       -0.002314, -0.000857, -0.000766, -0.000687, -0.000516, -0.000614,\n",
      "       0.017893, -0.001030, -0.010599, -0.000510, -0.005505, -0.003593,\n",
      "       -0.002458, -0.003352, -0.008409, -0.002221, -0.009452, -0.019225,\n",
      "       -0.036896, 0.091111, -0.001350, 0.042774, -0.001085, -0.002493,\n",
      "       -0.001675, -0.004089, -0.001412, -0.026219, -0.001337, -0.003115,\n",
      "       -0.017289, -0.002542, -0.001113, -0.000926, -0.001321, -0.000911,\n",
      "       -0.001893, -0.001488, -0.007886, 0.035370, -0.001025, -0.001409,\n",
      "       -0.002038, -0.001065, -0.002367, -0.001036, -0.000900, 0.014216,\n",
      "       -0.003073, -0.001304, -0.001180, -0.001582, -0.002583, -0.001474,\n",
      "       0.013376, -0.001116, -0.000876, -0.002086, -0.001770, -0.000710,\n",
      "       -0.002925, 0.018655, -0.000824, -0.002485, -0.001771, -0.002544,\n",
      "       -0.002575, -0.000955, -0.003483, -0.001094, -0.000971, -0.001241,\n",
      "       -0.000905, -0.000674, 0.007863, -0.000658, -0.001171, -0.000815,\n",
      "       -0.000579, -0.000849, -0.001429, 0.057582, -0.011918, -0.003039,\n",
      "       -0.001300, -0.002121, -0.001751, -0.003018, -0.031011, -0.001995,\n",
      "       -0.001794, -0.006373, 0.068962, -0.043150, -0.004731, -0.001232,\n",
      "       -0.002973, -0.004113, -0.002820, -0.001775, -0.001727, -0.001592,\n",
      "       -0.001224, -0.046642, -0.022755, 0.083423, -0.001467, -0.003397,\n",
      "       -0.001742, -0.002877, -0.001105, -0.009918, -0.000743, -0.002895,\n",
      "       -0.001266, -0.002167, -0.001929, -0.001010, 0.021781, -0.000746,\n",
      "       -0.001037, -0.013788, -0.001151, -0.019267, 0.050504, -0.004173,\n",
      "       -0.006240, -0.001533, -0.002233, -0.001081, -0.003792, -0.002910,\n",
      "       -0.000875, -0.004206, -0.000991, 0.019859, -0.000919, -0.002252,\n",
      "       -0.003117, -0.000795, -0.000898, -0.000936, -0.001330, -0.000889,\n",
      "       -0.000838, 0.010672, -0.000942, -0.000739, -0.000979, -0.003119,\n",
      "       -0.000801, -0.006191, -0.001517, -0.000807, -0.014594, 0.029158,\n",
      "       -0.001154, -0.001697, -0.000744, -0.001652, -0.000594, -0.002154,\n",
      "       -0.000617, 0.009677, -0.001677, -0.000850, -0.000599, -0.000554,\n",
      "       -0.001252, -0.001380, 0.024648, -0.002097, -0.008854, -0.000971,\n",
      "       -0.001032, -0.002022, -0.001866, -0.001296, -0.003762, -0.002748,\n",
      "       -0.005121, -0.001608, -0.003142, 0.030543, -0.002413, -0.005950,\n",
      "       -0.001221, -0.001072, -0.008561, -0.001456, -0.969767, -0.001583,\n",
      "       -0.001425, -0.002120, 0.983766, -0.001157, -0.001160, -0.000987,\n",
      "       -0.002426, -0.003141, -0.000867, -0.002662, -0.001796, -0.000788,\n",
      "       -0.001491, -0.020872, 0.040586, -0.000989, -0.002075, -0.009046,\n",
      "       -0.001007, -0.009887, -0.000903, -0.000810, 0.018604, -0.000986,\n",
      "       -0.001704, -0.001645, -0.000905, -0.000757, -0.001079, -0.002123,\n",
      "       0.015320, -0.001183, -0.002130, -0.002874, -0.001778, -0.002039,\n",
      "       -0.001290, -0.000823, -0.004182, 0.017251, -0.003363, -0.000699,\n",
      "       -0.004437, -0.000921, -0.000752, -0.000956, -0.001131, -0.000810,\n",
      "       -0.000889, -0.003100, -0.000961, 0.984131, -0.012490, -0.000858,\n",
      "       -0.962467, -0.000775, -0.001390, -0.001200, -0.004040, -0.001914,\n",
      "       -0.002877, -0.002248, -0.000927, -0.003463, 0.021041, -0.001932,\n",
      "       -0.000985, -0.002655, -0.003633, -0.001191, -0.002638, -0.004617,\n",
      "       -0.001227, -0.003117, -0.013893, -0.002650, 0.972209, -0.939243,\n",
      "       -0.001293, -0.006469, 0.140858, -0.002910, -0.003621, -0.002987,\n",
      "       -0.001226, -0.103790, -0.001324, -0.017239, 0.992281, -0.002506,\n",
      "       -0.002222, -0.001726, -0.001830, -0.001654, -0.003427, -0.001343,\n",
      "       -0.001655, -0.975918, -0.004320, -0.002076, -0.001795, -0.001675,\n",
      "       0.185898, -0.002285, -0.002000, -0.164470, -0.005496, -0.001779,\n",
      "       0.990454, -0.001578, -0.001246, -0.971612, -0.002332, -0.001179,\n",
      "       -0.002114, -0.001979, -0.005362, -0.003051, -0.004106, -0.000946,\n",
      "       -0.002887, -0.005165, -0.001051, -0.001939, 0.028573, -0.001852,\n",
      "       -0.005983, -0.004643]))\n"
     ]
    }
   ],
   "source": [
    "print('Policy gap',new_policy - theta_to_policy(theta,n,m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Reward', array([0.129623, 0.223922, 0.267149, 0.749682, 0.233013, 0.521648,\n",
      "       0.061685, 0.871179, 0.921278, 0.846656, 0.188503, 0.920552,\n",
      "       0.012439, 0.443440, 0.872636, 0.485601, 0.812311, 0.877579,\n",
      "       0.979165, 0.756940, 0.896464, 0.644017, 0.463837, 0.978372,\n",
      "       0.355300, 0.606278, 0.669149, 0.039861, 0.861896, 0.038052,\n",
      "       0.493838, 0.684726, 0.009325, 0.601250, 0.863318, 0.466640,\n",
      "       0.096066, 0.527843, 0.767550, 0.884475, 0.290646, 0.584947,\n",
      "       0.752086, 0.833800, 0.793640, 0.215385, 0.953700, 0.335579,\n",
      "       0.859089, 0.617466, 0.265021, 0.470517, 0.344735, 0.572722,\n",
      "       0.744880, 0.809061, 0.638783, 0.952026, 0.444460, 0.518705,\n",
      "       0.187390, 0.896650, 0.385241, 0.787003, 0.605292, 0.011310,\n",
      "       0.847703, 0.183989, 0.631642, 0.335048, 0.973776, 0.799205,\n",
      "       0.676659, 0.671391, 0.176502, 0.076607, 0.416499, 0.755531,\n",
      "       0.924367, 0.497020, 0.128191, 0.550441, 0.952301, 0.302637,\n",
      "       0.727448, 0.861948, 0.488582, 0.838048, 0.493905, 0.990251,\n",
      "       0.603058, 0.166345, 0.122670, 0.123668, 0.334201, 0.473723,\n",
      "       0.895023, 0.950708, 0.078564, 0.814652, 0.236101, 0.378245,\n",
      "       0.514422, 0.201338, 0.791804, 0.449117, 0.591423, 0.203297,\n",
      "       0.115858, 0.680872, 0.785401, 0.838846, 0.407542, 0.726809,\n",
      "       0.728422, 0.226319, 0.556187, 0.826004, 0.207704, 0.811565,\n",
      "       0.824156, 0.876894, 0.971503, 0.596800, 0.431212, 0.535725,\n",
      "       0.038218, 0.656314, 0.289781, 0.190508, 0.818932, 0.052663,\n",
      "       0.537664, 0.049828, 0.863848, 0.948666, 0.036643, 0.838125,\n",
      "       0.666242, 0.410532, 0.146980, 0.891851, 0.570100, 0.482860,\n",
      "       0.852481, 0.507251, 0.387608, 0.234008, 0.365074, 0.292702,\n",
      "       0.192766, 0.609325, 0.170608, 0.663628, 0.378854, 0.440250,\n",
      "       0.889891, 0.299458, 0.117583, 0.539978, 0.891822, 0.116539,\n",
      "       0.743684, 0.305547, 0.175471, 0.058929, 0.837853, 0.882852,\n",
      "       0.780942, 0.522995, 0.078338, 0.231418, 0.745731, 0.613687,\n",
      "       0.915073, 0.787095, 0.758256, 0.249266, 0.416692, 0.117283,\n",
      "       0.591565, 0.218539, 0.186091, 0.088574, 0.051235, 0.108472,\n",
      "       0.998108, 0.409763, 0.908860, 0.031127, 0.682530, 0.577986,\n",
      "       0.429415, 0.516390, 0.695704, 0.352724, 0.766127, 0.746030,\n",
      "       0.772813, 0.859644, 0.245823, 0.856168, 0.025776, 0.551546,\n",
      "       0.304560, 0.656966, 0.335354, 0.825787, 0.223458, 0.609565,\n",
      "       0.916673, 0.725024, 0.224503, 0.075483, 0.317125, 0.071740,\n",
      "       0.569741, 0.357944, 0.897479, 0.947640, 0.114143, 0.512384,\n",
      "       0.548607, 0.398628, 0.769801, 0.210240, 0.244443, 0.884786,\n",
      "       0.650363, 0.291281, 0.335958, 0.606093, 0.647814, 0.518874,\n",
      "       0.928541, 0.300557, 0.267310, 0.742970, 0.603555, 0.014704,\n",
      "       0.758735, 0.992525, 0.064473, 0.812027, 0.637204, 0.794506,\n",
      "       0.731658, 0.287296, 0.803481, 0.364034, 0.273795, 0.565458,\n",
      "       0.211641, 0.255534, 0.998689, 0.136279, 0.445044, 0.264638,\n",
      "       0.019869, 0.280786, 0.373223, 0.903595, 0.865403, 0.660594,\n",
      "       0.322270, 0.478125, 0.473675, 0.580247, 0.850570, 0.504290,\n",
      "       0.223494, 0.605471, 0.777613, 0.671876, 0.594122, 0.000575,\n",
      "       0.423550, 0.507297, 0.477968, 0.222644, 0.275742, 0.265973,\n",
      "       0.128306, 0.868462, 0.889048, 0.903118, 0.235933, 0.589121,\n",
      "       0.413605, 0.544971, 0.413028, 0.921557, 0.090785, 0.760655,\n",
      "       0.354473, 0.618545, 0.557685, 0.257133, 0.984497, 0.167181,\n",
      "       0.090082, 0.709277, 0.182085, 0.725438, 0.808742, 0.608455,\n",
      "       0.658279, 0.291900, 0.424316, 0.153220, 0.883029, 0.640724,\n",
      "       0.120163, 0.731623, 0.064177, 0.902985, 0.038032, 0.540707,\n",
      "       0.886039, 0.016448, 0.257159, 0.132866, 0.649616, 0.084665,\n",
      "       0.150785, 0.947466, 0.157466, 0.109365, 0.469493, 0.871519,\n",
      "       0.090882, 0.749709, 0.422696, 0.140146, 0.750133, 0.925910,\n",
      "       0.348031, 0.526962, 0.016980, 0.510136, 0.212082, 0.689300,\n",
      "       0.142242, 0.995161, 0.676705, 0.282566, 0.128494, 0.104891,\n",
      "       0.516295, 0.709572, 0.957289, 0.544989, 0.952058, 0.190304,\n",
      "       0.198534, 0.633081, 0.494004, 0.270655, 0.807911, 0.687505,\n",
      "       0.954763, 0.407178, 0.767742, 0.963364, 0.695941, 0.817845,\n",
      "       0.306880, 0.065101, 0.951021, 0.392858, 0.949315, 0.489416,\n",
      "       0.333259, 0.477779, 0.964359, 0.315175, 0.134982, 0.015015,\n",
      "       0.571093, 0.664186, 0.096922, 0.811595, 0.618657, 0.066762,\n",
      "       0.455988, 0.912810, 0.985211, 0.185152, 0.628682, 0.866231,\n",
      "       0.413951, 0.943230, 0.333098, 0.078100, 0.991087, 0.273454,\n",
      "       0.584932, 0.563055, 0.321521, 0.138289, 0.268409, 0.496864,\n",
      "       0.828356, 0.311376, 0.451213, 0.651206, 0.474636, 0.536519,\n",
      "       0.434103, 0.028299, 0.781315, 0.961207, 0.728796, 0.014114,\n",
      "       0.802120, 0.303543, 0.120569, 0.330114, 0.574582, 0.185215,\n",
      "       0.039406, 0.729054, 0.046213, 0.975129, 0.895965, 0.152769,\n",
      "       0.977408, 0.047425, 0.472463, 0.284037, 0.740375, 0.534373,\n",
      "       0.736394, 0.540054, 0.013940, 0.835504, 0.884349, 0.552516,\n",
      "       0.052825, 0.653304, 0.622201, 0.046305, 0.437058, 0.572200,\n",
      "       0.019314, 0.505249, 0.830699, 0.417843, 0.831039, 0.827275,\n",
      "       0.072438, 0.759711, 0.995008, 0.614776, 0.726550, 0.568497,\n",
      "       0.112594, 0.921454, 0.115033, 0.865949, 0.905936, 0.496342,\n",
      "       0.408375, 0.355256, 0.322446, 0.356152, 0.563378, 0.067542,\n",
      "       0.286339, 0.817123, 0.717264, 0.394715, 0.292747, 0.300045,\n",
      "       0.998489, 0.474858, 0.426467, 0.942845, 0.771037, 0.349624,\n",
      "       0.773038, 0.264025, 0.134295, 0.744382, 0.503860, 0.121178,\n",
      "       0.353790, 0.339066, 0.611552, 0.465085, 0.857613, 0.071841,\n",
      "       0.651998, 0.818170, 0.110739, 0.610500, 0.942929, 0.540841,\n",
      "       0.855755, 0.739902]))\n"
     ]
    }
   ],
   "source": [
    "print('Reward',reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,  100,  200,  300,  400,  500,  600,  700,  800,  900, 1000,\n",
       "       1100, 1200, 1300, 1400, 1500, 1600, 1700, 1800, 1900, 2000, 2100,\n",
       "       2200, 2300, 2400, 2500, 2600, 2700, 2800, 2900, 3000, 3100, 3200,\n",
       "       3300, 3400, 3500, 3600, 3700, 3800, 3900, 4000, 4100, 4200, 4300,\n",
       "       4400, 4500, 4600, 4700, 4800, 4900, 5000, 5100, 5200, 5300, 5400,\n",
       "       5500, 5600, 5700, 5800, 5900, 6000, 6100, 6200, 6300, 6400, 6500,\n",
       "       6600, 6700, 6800, 6900, 7000, 7100, 7200, 7300, 7400, 7500, 7600,\n",
       "       7700, 7800, 7900, 8000, 8100, 8200, 8300, 8400, 8500, 8600, 8700,\n",
       "       8800, 8900, 9000, 9100, 9200, 9300, 9400, 9500, 9600, 9700, 9800,\n",
       "       9900])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(0, 10000, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x10d13fc50>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGUMwAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x109d67890>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f = plt.figure\n",
    "plt.plot(np.array(gap))\n",
    "plt.title('Optimality gap during training')\n",
    "plt.ylabel('Optimality gap')\n",
    "plt.xlabel('Iteration number/100')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
